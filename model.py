import torch
import torch.nn as nn
'''
3维图像融合成2维图像使用MAE的方式，自监督阶段也使用MAE的方式。
3M图像256*304*304，按照16*16*16划分，共5776块，是196块的29倍；如何随机丢块。每个块大小像素点4096个，是768的5.3倍。768是三通道算出来的，4096是单通道算出来的
# TODO 方法1。图像块按照16*16*16划分之后沿着深度方向向下遍历；然后沿着高度方向再向右遍历；最后沿着宽度方向向前遍历。每个16*16*16的块输出1*16*16的平面图像，
纵向的所有块最终输出16个1*16*16的平面图像，将这些拼接成一个16*16*16的块再输入。

假设换个思路，对256*304的图像编码输出1*304的向量，然后将304张图片的输出结果拼接在一起作为融合图像。但是这样似乎不算充分利用体数据。
transformer编码器的输入似乎是768，所以
如果图像块是16*16*16，那
'''



class 自注意力(nn.Module):
    """
    多头注意力机制模块
    """
    def __init__(self, 嵌入向量的维度, 头数量):
        """

        :param 嵌入向量的维度:
        :param 头数量:
        """
        super(自注意力, self).__init__()
        self.头数量 = 头数量 # 多头注意力的数量

class MLP(nn.Module):
    def __init__(self, 输入特征维度):
        super(MLP, self).__init__()
        self.输入特征维度 = 输入特征维度